---
layout: post
title: "Scribe日志收集系统介绍"
description: "Scribe日志收集系统介绍"
category: "tech"
tags: [scribe,日志服务器]
tagline: "2016-04-15"

---
{% include JB/setup %}

http://dongxicheng.org/search-engine/scribe-intro/
  
1、  概述  
Scribe是facebook开源的日志收集系统，在facebook内部已经得到大量的应用。它能够从各种日志源上收集日志，存储到一个中央存 储系统（可以是NFS，分布式文件系统等）上，以便于进行集中统计分析处理。它为日志的“分布式收集，统一处理”提供了一个可扩展的，高容错的方案。当中 央存储系统的网络或者机器出现故障时，scribe会将日志转存到本地或者另一个位置，当中央存储系统恢复后，scribe会将转存的日志重新传输给中央 存储系统。
scribe的相关资料比较少，主要限于它的主页（见参考资料1）。此外，它的安装比较复杂，可参见我的另一篇博文：scribe日志收集系统安装方法介绍。

2、 架构  
![](/images/scribe1.jpg)  
如上图所示，Scribe从各种数据源上收集数据，放到一个共享队列上，然后push到后端的中央存储系统上。当中央存储系统出现故障时，scribe可以暂时把日志写到本地文件中，待中央存储系统恢复性能后，scribe把本地日志续传到中央存储系统上。
需要注意的是，各个数据源须通过thrift（由于采用了thrift，客户端可以采用各种语言编写，关于thrift框架，参见我的这篇博文：Thrift框架介绍） 向scribe传输数据（每条数据记录包含一个category和一个message）。可以在scribe配置用于监听端口的thrift线程数（默认 为3）。在后端，scribe可以将不同category的数据存放到不同目录中，以便于进行分别处理。后端的日志存储方式可以是各种各样的store， 包括file（文件），buffer（双层存储，一个主储存，一个副存储），network（另一个scribe服务器），bucket（包含多个 store，通过hash的将数据存到不同store中），null(忽略数据)，thriftfile（写到一个Thrift TFileTransport文件中）和multi（把数据同时存放到不同store中）。

3、  scribe中各种store介绍  
（1）file  
将日志写到文件或者NFS中。目前支持两种文件格式，即std和hdfs，分别表示普通文本文件和HDFS。可配置的选项有：

	max_size：文件大小上限，即当文件大小达到max_size时，创建新的文件继续存储数据。
	rotate_period：文件创建周期，可以是hourly，daily，never和number[sufix]。sufix可以是s（second），m（minute），h（hour），d（day），w（week）。
	sub_directory：子目录名字
	base_filename：文件前缀，如news，则会依次将数据存储到文件news_20110403_00000，news_20110403_00001，……
	
（2） buffer  
这是最常用的一种store。该store中包含两个子store，其中一个是primary store，另一个是secondary store。日志会优先写到primary store中，如果primary store出现故障，则scribe会将日志暂存到secondary store中，待primary store恢复性能后，再将secondary store中的数据拷贝到primary store中。其中，secondary store仅支持两种store，一个是file，另一个是hdfs。

    port=1464
    max_msg_per_second=2000000
    check_interval=1
    max_queue_size=100000000
    num_thrift_server_threads=2
    # DEFAULT - write all messages to hadoop hdfs
    category=default
    type=buffer
    target_write_size=20480
    max_write_interval=1
    buffer_send_rate=1
    retry_interval=30
    retry_interval_range=10
    type=file
    fs_type=hdfs
    file_path=hdfs://localhost:9000/scribedata
    create_symlink=no
    use_hostname_sub_directory=yes
    base_filename=thisisoverwritten
    max_size=1000000000
    rotate_period=daily
    rotate_hour=0
    rotate_minute=5
    add_newlines=1
    type=file
    fs_type=std
    file_path=/tmp/scribe-central-hdfs
    base_filename=thisisoverwritten
    max_size=3000000

（3） null  
这也是一种常用的store。用户可以在配置文件中配置一种叫default的category，如果数据所属的category没有在配置文件中设置相应的存储方式，则该数据会被当做default。如果用户想忽略这样的数据，可以将它放入null store中。
其它store的介绍，可参见参考资料1。  
需要注意的是，Scribe会将数据首先缓存到buffer中，待buffer满后再flush到HDFS上。当数据量非常少时，由于缓存的原因， 部分数据可能未写到HDFS中，这时用户可以调整scribe的相关配置参数或者关闭scribe（如减小max_size），使数据全部写到HDFS 中。如果用户采用减小max_size的方案，此时需要注意，HDFS不能很好的保存小文件（可能会丢失数据,见参考资料3）。

4、  总结  
总起来说，scribe为日志收集提供了一种容错且可扩展的方案。scribe可以从不同数据源，不同机器上收集日志，然后将它们存入一个中央存储 系统，以便于进一步处理。当采用HDFS作为中央系统时，可以进一步利用Hadoop进行处理数据，于是scribe+HDFS+MapReduce方案 便诞生了。具体如下图（摘自参考资料2）所示：  
![](/images/scribe2.png)  
由于scribe资料比较少，网上讨论也不是十分活跃，不少人转用其它一些日志系统，比如：rsyslog 和 Chukwa。

5、  参考资料

	（1）scribe主页：https://github.com/facebook/scribe
	（2）scribe介绍 ：http://blog.octo.com/en/scribe-a-way-to-aggregate-data-and-why-not-to-directly-fill-the-hdfs/
	（3）HDFS小文件问题：http://www.cloudera.com/blog/2009/02/the-small-files-problem/
	（4）Scribe所有资料的汇总：http://sameerparwani.com/posts/facebook-scribe-server-documentation-and-tutorials

